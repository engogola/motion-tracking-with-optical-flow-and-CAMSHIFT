{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPstbLAujjvSqFmPSlRa7Yf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/engogola/motion-tracking-with-optical-flow-and-CAMSHIFT/blob/main/motiontracking_with_Opticalflow_and_CAMSHIFT(ritchie).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Motion tracking with meanshift and CAMSHIFT"
      ],
      "metadata": {
        "id": "lXJdxUSHX5SG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qmj-NWMPIrf"
      },
      "source": [
        "# Our Setup, Import Libaries, Create our Imshow Function and Download our Images\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Define our imshow function\n",
        "def imshow(title = \"Image\", image = None, size = 10):\n",
        "    w, h = image.shape[0], image.shape[1]\n",
        "    aspect_ratio = w/h\n",
        "    plt.figure(figsize=(size * aspect_ratio,size))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "!wget https://github.com/makelove/OpenCV-Python-Tutorial/raw/master/data/slow.flv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPJMzyqxPuTC"
      },
      "source": [
        "cap = cv2.VideoCapture('slow.flv')\n",
        "\n",
        "# take first frame of the video\n",
        "ret,frame = cap.read()\n",
        "\n",
        "# Get the height and width of the frame (required to be an interger)\n",
        "width = int(cap.get(3))\n",
        "height = int(cap.get(4))\n",
        "\n",
        "# Define the codec and create VideoWriter object. The output is stored in '*.avi' file.\n",
        "out = cv2.VideoWriter('car_tracking_mean_shift.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 30, (width, height))\n",
        "\n",
        "# setup initial location of window\n",
        "r,h,c,w = 250,90,400,125  # simply hardcoded the values\n",
        "track_window = (c,r,w,h)\n",
        "\n",
        "# set up the ROI for tracking\n",
        "roi = frame[r:r+h, c:c+w]\n",
        "hsv_roi =  cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
        "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
        "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
        "\n",
        "# Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
        "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
        "\n",
        "while(1):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret == True:\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
        "\n",
        "        # apply meanshift to get the new location\n",
        "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
        "\n",
        "        # Draw it on image\n",
        "        x,y,w,h = track_window\n",
        "        img2 = cv2.rectangle(frame, (x,y), (x+w,y+h), (255,255,255),2)\n",
        "        out.write(img2)\n",
        "        #imshow('Tracking', img2)\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kVcEf2uCaMiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5LFFioeGrXz"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('car_tracking_cam_shift.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "motion tracking using Optical flow algorithm"
      ],
      "metadata": {
        "id": "WdIX1ZIdcycc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jqsxYKuPc6ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4hb4D4aSLd-"
      },
      "source": [
        "# Our Setup, Import Libaries, Create our Imshow Function and Download our Images\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Define our imshow function\n",
        "def imshow(title = \"Image\", image = None, size = 10):\n",
        "    w, h = image.shape[0], image.shape[1]\n",
        "    aspect_ratio = w/h\n",
        "    plt.figure(figsize=(size * aspect_ratio,size))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "!wget https://github.com/rajeevratan84/ModernComputerVision/raw/main/walking_short_clip.mp4\n",
        "!wget https://github.com/rajeevratan84/ModernComputerVision/raw/main/walking.avi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Lucas-Kanade Optical Flow Algorithm\n",
        "Optical flow is the pattern of apparent motion of image objects between two consecutive frames caused by the movemement of object or camera. It is 2D vector field where each vector is a displacement vector showing the movement of points from first frame to second. Consider the image below (Image Courtesy: Wikipedia article on Optical Flow).\n",
        "\n"
      ],
      "metadata": {
        "id": "V-XlJvK3dB6L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5y7cpRyudH4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXDTVyssSKLP"
      },
      "source": [
        "# Load video stream, short clip\n",
        "#cap = cv2.VideoCapture('walking_short_clip.mp4')\n",
        "\n",
        "# Load video stream, long clip\n",
        "cap = cv2.VideoCapture('walking.avi')\n",
        "\n",
        "# Get the height and width of the frame (required to be an interger)\n",
        "width = int(cap.get(3))\n",
        "height = int(cap.get(4))\n",
        "\n",
        "# Define the codec and create VideoWriter object. The output is stored in '*.avi' file.\n",
        "out = cv2.VideoWriter('optical_flow_walking.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 30, (width, height))\n",
        "\n",
        "# Set parameters for ShiTomasi corner detection\n",
        "feature_params = dict( maxCorners = 100,\n",
        "                       qualityLevel = 0.3,\n",
        "                       minDistance = 7,\n",
        "                       blockSize = 7 )\n",
        "\n",
        "# Set parameters for lucas kanade optical flow\n",
        "lucas_kanade_params = dict( winSize  = (15,15),\n",
        "                  maxLevel = 2,\n",
        "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "# Create some random colors\n",
        "# Used to create our trails for object movement in the image\n",
        "color = np.random.randint(0,255,(100,3))\n",
        "\n",
        "# Take first frame and find corners in it\n",
        "ret, prev_frame = cap.read()\n",
        "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Find inital corner locations\n",
        "prev_corners = cv2.goodFeaturesToTrack(prev_gray, mask = None, **feature_params)\n",
        "\n",
        "# Create a mask image for drawing purposes\n",
        "mask = np.zeros_like(prev_frame)\n",
        "\n",
        "while(1):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret == True:\n",
        "      frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "      # calculate optical flow\n",
        "      new_corners, status, errors = cv2.calcOpticalFlowPyrLK(prev_gray,\n",
        "                                                            frame_gray,\n",
        "                                                            prev_corners,\n",
        "                                                            None,\n",
        "                                                            **lucas_kanade_params)\n",
        "\n",
        "      # Select and store good points\n",
        "      good_new = new_corners[status==1]\n",
        "      good_old = prev_corners[status==1]\n",
        "\n",
        "      # Draw the tracks\n",
        "      for i,(new,old) in enumerate(zip(good_new, good_old)):\n",
        "          a, b = new.ravel()\n",
        "          c, d = old.ravel()\n",
        "          mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
        "          frame = cv2.circle(frame, (a,b), 5, color[i].tolist(),-1)\n",
        "\n",
        "      img = cv2.add(frame,mask)\n",
        "\n",
        "      # Save Video\n",
        "      out.write(img)\n",
        "      # Show Optical Flow\n",
        "      #imshow('Optical Flow - Lucas-Kanade',img)\n",
        "\n",
        "      # Now update the previous frame and previous points\n",
        "      prev_gray = frame_gray.copy()\n",
        "      prev_corners = good_new.reshape(-1,1,2)\n",
        "\n",
        "    else:\n",
        "      break\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RmNNFhoKe6t"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('optical_flow_walking.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkdstCuuMhc2"
      },
      "source": [
        "HTML(\"\"\"\n",
        "<video controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dense optimal Flow"
      ],
      "metadata": {
        "id": "hHXvwVr2dv9r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a-HIC_c6eD6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Vq4hQKU9mG"
      },
      "source": [
        "# Load video stream, short clip\n",
        "#cap = cv2.VideoCapture('walking_short_clip.mp4')\n",
        "\n",
        "# Load video stream, long clip\n",
        "cap = cv2.VideoCapture('walking.avi')\n",
        "\n",
        "# Get the height and width of the frame (required to be an interger)\n",
        "width = int(cap.get(3))\n",
        "height = int(cap.get(4))\n",
        "\n",
        "# Define the codec and create VideoWriter object. The output is stored in '*.avi' file.\n",
        "out = cv2.VideoWriter('dense_optical_flow_walking.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 30, (width, height))\n",
        "\n",
        "# Get first frame\n",
        "ret, first_frame = cap.read()\n",
        "previous_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
        "hsv = np.zeros_like(first_frame)\n",
        "hsv[...,1] = 255\n",
        "\n",
        "while True:\n",
        "\n",
        "    # Read of video file\n",
        "    ret, frame2 = cap.read()\n",
        "\n",
        "    if ret == True:\n",
        "      next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "      # Computes the dense optical flow using the Gunnar Farneback’s algorithm\n",
        "      flow = cv2.calcOpticalFlowFarneback(previous_gray, next,\n",
        "                                          None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "      # use flow to calculate the magnitude (speed) and angle of motion\n",
        "      # use these values to calculate the color to reflect speed and angle\n",
        "      magnitude, angle = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "      hsv[...,0] = angle * (180 / (np.pi/2))\n",
        "      hsv[...,2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
        "      final = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "      # Save Video\n",
        "      out.write(final)\n",
        "      # Show our demo of Dense Optical Flow\n",
        "      #imshow('Dense Optical Flow', final)\n",
        "\n",
        "      # Store current image as previous image\n",
        "      previous_gray = next\n",
        "\n",
        "    else:\n",
        "      break\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I15nTaPUexlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dmuaJNYMzkM"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('dense_optical_flow_walking.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--2AzrAYM0sm"
      },
      "source": [
        "HTML(\"\"\"\n",
        "<video controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}